# Project 1.2 – Zero-Shot vs Few-Shot Prompting (GPT-5)

This project demonstrates the difference between zero-shot and few-shot prompting when working with GPT-5. The goal is to show how providing examples (few-shot) changes the model’s output compared to giving no examples (zero-shot), improving consistency and control.

## Files
- zero_shot.md — Task without prior examples.
- few_shot.md — Same task but with guiding examples.

## Why this matters
- Zero-shot: faster setup, but the model may apply its own implicit criteria.
- Few-shot: adds explicit guidance, yielding more consistent, reproducible outputs.

## Key takeaway
Prompt engineering is not only about “asking”—it’s about specifying format, criteria, and examples to steer model behavior toward your desired outcome.
